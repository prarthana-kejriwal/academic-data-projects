---
output:
  word_document: default
  pdf_document: default
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


#### Importing Data

```{r, eval = TRUE}
assg1 <- read.csv("assg1.csv")
```

#### Summarizing Original Data

```{r}
library(psych)
describe(assg1)
```

#### Scaling Data and Summarizing Data

```{r}
assg1.sc <- assg1
assg1.sc[, 2:6] <- scale(assg1.sc[,2:6])
describe(assg1.sc)
```

The Data set has 30 respondents who have scored 5 questions (X1 through X5) on a scale of 1-9. The original data had different means and standard deviations across scores for X1 through X3. So to ensure that the data are comparable, we scaled the data for columns 2 to 6 which can be confirmed by the summary statistics of assg1. Notice that the means of all the ratings variables are now zero and the standard deviations are all 1.



#### Matrix of correlations

```{r}
cor(assg1.sc[, 2:6])
```


#### Install relevant packages

```{r, eval = FALSE}
install.packages("corrplot")
```

#### Plot of correlations

```{r}
library(corrplot)
corrplot(cor(assg1.sc[, 2:6]), order="hclust")
```


Together, the correlation analysis suggests that -- 1) there is a fair amount of correlation between different variables, and 2) some common themes emerge, e.g., People who need to feel respected as a part of their shopping experience and won't return to the store in case they feel disrespected are also the ones that are more likely to ask for advise during shopping, and need a salesperson around. (X1 and X3 have strong positive correlation). Also, this set of people are less likely to find salespeople who fawn over them irritating. 
In addition, people who care lesser for the way things are displayed are more likely to find discount stores cost effective than departmental stores.



#### Perfroming PCA and importance of components

```{r}
assg1.pc = prcomp(assg1.sc[,2:6])
summary(assg1.pc)
```

The second row of the table above tells us how much of the variance in the data is explained by each component, in decreasing order. Thus, the first component explains 53.43\% of the variance in the data, the second component explains 37.04\%, and so on. The third row denotes the cumulative variance. In our example, the first and second components explain 90.48\% of the variance in the data. In other words, we can reduce the dimensionality of our original set of five variables to two, and still retain 90.48\% of the explanatory power. 

However, the above table does not tell us how the factors generated by the PCA relate to the original attributes. To get that information, we use the following command. 

#### Relationship between the original attributes  and the new factors
```{r}
assg1.pc$rotation
```


$$PC1 = -0.555 \cdot X1 + 0.571 \cdot X2 - 0.58 \cdot X3 - 0.017 \cdot X4 + 0.174 \cdot X5 $$

$$PC2 = 0.232 \cdot X1 + 0.212 \cdot X2 + 0.157 \cdot X3 + 0.686 \cdot X4 + 0.637 \cdot X5$$ 

$$PC3 = -0.279 \cdot X1 - 0.183 \cdot X2 + 0.311 \cdot X3 - 0.561 \cdot X4 + 0.691 \cdot X5$$ 

$$PC4 = -0.723 \cdot X1 - 0.462 \cdot X2 + 0.187 \cdot X3 + 0.461 \cdot X4 - 0.125 \cdot X5$$ 

$$PC5 = 0.191 \cdot X1 - 0.618 \cdot X2 - 0.713 \cdot X3 + 0.041 \cdot X4 + 0.267 \cdot X5$$ 


```{r}
plot(assg1.pc, type='l')
```

#### Decide how many factors to keep

We decided to keep 2 factors for the following reasons:

1) The common rule of thumb is to keep factors that are above the "kink" in the scree-plot. Here, that would translate to two factors.  
2) The second criteria often used is to keep factors which are over 1 in the scree plot. Only 2 factors have Eigen value > 1 and hence explain at least the same amount of variance as explained by a single variable. This criteria also gives us two factors in this case. 
The first two components explain $~90.48\%$ of the variance in the data which is sufficiently representative. Thus, we can reduce the dimensionality of our data from five to two in this example.

PC1: Independent shoppers

It represents the independence with which a person shops, going from needs high level of service and attention on the left to can shop independently, with just basic courteous service on the right.

The main idea here is that PC1 seems to be heavily positively correlated with x2 (requires courteous but not fawning salesmen) and strong negatively correlated with x1 (requires respect) and x3 (requires personal advise and service) . A respondent with a negative PC1 will indicate high scores in x1 and x3 and low scores in x2.


PC2: Frugal shoppers

It represents the frugality of the shopper, going from being a bargain or deal-hunter on the top to being price insensitive towards the bottom.

The main idea here is that PC2 seems to be most positively correlated with x4(does not care about fancy displays) and x5 (finds good deals at discount stores). This indicates that that a respondent with high PC2 cares more about economical deals and value for money.


#### We can plot the ratings on the two main principal components using `biplot' as follows:

```{r}
biplot(assg1.pc,xlab = "Independent Shopper(PC1)", ylab = "Frugal Shopper(PC2)", xlim=c(-.4,.4), ylim=c(-.4,.4))
abline(h = 0, v = 0, col = "gray60")
```

This map tells us that X1 and X3 are highly correlated attributes and so are X4 and X5, they cluster together in this graph. X2 is different from other attributes.



#### Predict

We first generate a new dataset where the ratings are now transformed to the new factors.

```{r}
assg1.pred <- predict(assg1.pc, assg1.sc)
assg1.pca <- data.frame(assg1[,1])
colnames(assg1.pca) <- "Resp"
assg1.pca[, 2:6] <- assg1.pred
head(assg1.pca)
```

#### Plot the two-dimensional map

We take the ratings for the first two factors and plot them on a two-dimensional plot.

```{r}
plot(assg1.pca$V2, assg1.pca$V3, xlab = "Independent Shopper(PC1)", ylab = "Frugal Shopper(PC2)", main = "Positioning",xlim=c(-3,3), ylim=c(-3,3))
text(assg1.pca$V2, assg1.pca$V3, labels=assg1.pca$Resp)
abline(h = 0, v = 0, col = "gray60")
```

To segment the market, we use k-means clustering, which is an unsupervised learning algorithm that tries to segment data based on the similarity.  It classifies respondents in the market in multiple groups (i.e., clusters), such that respondents within the same cluster are as similar as possible, i.e., the total intra-cluster variation (total within-cluster variation) is minimized.

However, it requires us to specify the number of clusters to be generated. For this, we use the elbow method. The total within-cluster sum of square (wss) measures the compactness of the clustering and we want it to be as small as possible.

#### Elbow Method for determining optimal clusters

```{r}
mydata <- assg1.pca[,2:3]
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:21) 
  wss[i] <- sum(kmeans(mydata, centers=i)$withinss)
plot(1:21, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares")
```

The location of a bend (knee) in the plot is generally considered as an indicator of the appropriate number of clusters, and we see from the above that 3 is a reasonable number of segments, since the marginal drop in wss after 3 is small.

#### k-means clustering (where k=3)

```{r}
set.seed(1)
clus<-kmeans(assg1.pca[,2:3],3)
assg1.pca$Segment <- as.factor(clus$cluster)
plot(assg1.pca$V2, assg1.pca$V3,pch=19,col=assg1.pca$Segment,xlab = "Independent Shopper(PC1)", ylab = "Frugal Shopper(PC2)", xlim=c(-3,3), ylim=c(-3,3))
abline(h = 0, v = 0, col = "gray60")
```

We find that the respondents can be categorized into 3 segments that are distinct from each other. 


###  The characteristics of each segment and the relationship between the segment characteristics and the original attributes.

Based on our earlier naming nomenclature, the x-axis represents the independence with which a person shops, going from needs service and attention on the left to can shop independently on the right.

The y-axis represents the frugality of the shopper, going from being a bargain or deal-hunter on the top to being price insensitive towards the bottom.

Based on this, each segment can be characterized as :

Category 3 (in green): Frugal and Independent shoppers that need good prices and deals but do not need as much support while shopping.

Category 2 (in red) : Dependent shoppers (Irrespective of frugality). They generally demand salesman's service while shopping, irrespective whether they are price conscious or not.

Category 1 (in black) : Independent and Less price sensitive shoppers. These shoppers do not care much about deals and also do not require salesmen service and attention.

The segment for each respondent is saved in assg1.pca.

Going back to the original attributes,

- The respondents in category 3 seems to be favorable for discount stores. They have given high scores in x2, x4 and x5 indicating that they do not care about fancy displays nor do they need fawning salesmen and find the discount stores to have good deals.

- The respondents in category 2 seems to be favorable for departmental stores for higher levels of service. These respondents have given high scores in X1 and X3 indicating that they want respect and need salesmen around to answer their questions.

- The respondents in category 1 have given very high scores for x2 and either 0 or low scores for X1,X3,X4 and X5, indicating that they just prefer courteous salesmen. They do not care much about deals or high level of personal service.


### Most profitable segment and the size of this segment (in percentage).

Category 1(in black) should be the most profitable category since these customers do not shop with a bargaining mindset and also do not need service/ salesperson support for their shopping. 

Providing deals to the customers could limit revenue for a company and providing high levels of service is costly. Therefore customers who require neither deals nor high level of services should be the most profitable one. 

#### Calculating size of the segment

```{r}

FreqTable <- as.data.frame(table(assg1.pca$Segment))
FreqTable$Pct <- (FreqTable$Freq / sum(FreqTable$Freq))*100
FreqTable

```

However, the size of this segment is 20%. (6 respondents in segment 1 out of 30)